{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "explore_dataset.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "PDDqFd8hon3v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1> Get to know the project dataset, explore it, and prepare it for analysis </h1>\n",
        "\n",
        "In this notebook, you will be working with a dataset about taxi rides in New York City. The dataset is hosted on Google Cloud's BigQuery serverless data warehouse. You will learn how to authenticate with Google Cloud from this Jupyter notebook enviroment and then use SQL and BigQuery APIs to retrieve a sample taxi fare dataset. Remember that your goal is to build a machine learning model that will predict taxi fares in New York City so that riders know approximately how much they will be charged before they take a cab. You will explore and clean up the dataset, prepare it for further processing, and will use Python along with libraries like Pandas and Seaborn to help you.\n",
        "\n",
        "\n",
        "---\n",
        "Before you start, **make sure that you are logged in with your student account**. Otherwise you may incur Google Cloud charges for using this notebook. \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "To confirm that you are logged in with your student account, check that you see a letter S in a circle located in the upper right hand corner of this notebook like in the screenshot below. Of course the color around your letter S might not be exactly the same ;)\n",
        "\n",
        "If you are not sure if you are logged in with your student account, close all your private (i.e. incognito/anonymous) windows, open a new one,  log in [here](https://console.cloud.google.com) using the student credentials you got earlier, and finally return back to this page to continue with the notebook.\n",
        "\n",
        "![](https://i.imgur.com/PfSHVAb.png)"
      ]
    },
    {
      "metadata": {
        "id": "Wq75B91eon3y",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import shutil\n",
        "from google.cloud import bigquery\n",
        "\n",
        "#@markdown Copy-paste your GCP Project ID in the following field:\n",
        "\n",
        "\n",
        "PROJECT = \"\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown Next, use Shift-Enter to run this cell and to complete authentication.\n",
        "\n",
        "try:  \n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()  \n",
        "  print(\"AUTHENTICATED\")\n",
        "except:\n",
        "  print(\"FAILED to authenticate\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KrQm6_sHm8Ho",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h3> Sample data from BigQuery </h3>\n",
        "\n",
        "The taxi dataset for this project is a BigQuery public dataset. To review the dataset schema you will need to open the link at the end of the next paragraph, accept the terms & conditions, select your GCP project by clicking on the \"Select a project\" dropdown as shown on the following screenshot, and refresh your page.\n",
        "\n",
        "![](https://i.imgur.com/0sEOwMv.png)\n",
        "\n",
        "After you click on the link at the end of this paragraph, take a look at the schema and the field names. Switch to the Details tab to verify that the number of rows is about 1.1  billion and then switch to the Preview tab to sample a few rows. Here's the link: <a href=\"https://console.cloud.google.com/bigquery?p=nyc-tlc&d=yellow&t=trips&page=table\">NYC taxi fare dataset</a>\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "qJ2yoW-hon39",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here's a SQL query to sample 10 rows of data via BigQuery APIs. The SQL statement uses the LIMIT keyword to restrict the sample size to 10 rows. With this approach there are no guarantees about which records are returned or about their order. Notice that the code in the next cell is using BigQuery APIs and then stores the response in a Pandas dataframe variable named trips."
      ]
    },
    {
      "metadata": {
        "id": "t9xPjpPDpQGU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bq = bigquery.Client(project=PROJECT)\n",
        "\n",
        "trips = bq.query('''\n",
        "  SELECT \n",
        "    pickup_datetime, \n",
        "    pickup_longitude, \n",
        "    pickup_latitude, \n",
        "    dropoff_longitude,\n",
        "    dropoff_latitude, \n",
        "    passenger_count, \n",
        "    trip_distance, \n",
        "    tolls_amount, \n",
        "    fare_amount,\n",
        "    total_amount \n",
        "  FROM `nyc-tlc.yellow.trips` \n",
        "  LIMIT 10\n",
        "  ''').to_dataframe()\n",
        "\n",
        "trips"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YQqW7P1zon4G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's increase the number of records and do some neat graphs.  To properly sample the dataset, hash the pickup time and return 1 in 100,000 records. Since there are roughly 1 billion records in the data, you should get back approximately 10,000 records."
      ]
    },
    {
      "metadata": {
        "id": "TsMh2Gg4on4I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "EVERY_N = 100000\n",
        "\n",
        "trips = bq.query('''\n",
        "  SELECT\n",
        "    pickup_datetime,\n",
        "    pickup_longitude, pickup_latitude, \n",
        "    dropoff_longitude, dropoff_latitude,\n",
        "    passenger_count,\n",
        "    trip_distance,\n",
        "    tolls_amount,\n",
        "    fare_amount,\n",
        "    total_amount\n",
        "  FROM\n",
        "    `nyc-tlc.yellow.trips`\n",
        "  WHERE\n",
        "    #notice that the string (bytes) of the pickup_datetime\n",
        "    #are hashed to INT64 and then converted to its absolute (positive) value.\n",
        "    #The positive INT64 value is then divided by EVERY_N and\n",
        "    #only the rows where the remainder is 1 are returned\n",
        "    MOD(ABS(FARM_FINGERPRINT(STRING(pickup_datetime))), %d) = 1\n",
        "''' % (EVERY_N)).to_dataframe()\n",
        "\n",
        "trips[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gy1YHVQyon4O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h3> Exploring data </h3>\n",
        "\n",
        "Let's explore this dataset and clean it up as necessary. The following cells use Python Seaborn package to visualize graphs and Pandas to do the slicing and filtering of data."
      ]
    },
    {
      "metadata": {
        "id": "hEZzrLjNon4Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ax = sns.regplot(x=\"trip_distance\", y=\"fare_amount\", fit_reg=False, ci=None, truncate=True, data=trips)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "alDiJUy3on4W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Hmm ... do you see something wrong with the data that needs addressing?\n",
        "\n",
        "It appears that there is bogus data that is being coded as zero distance and some fare amounts that are definitely illegitimate. Let's remove them from our analysis. You can do this by modifying the SQL statement to keep just the trips that are longer than zero miles and with fare amounts that are at least the minimum cab fare ($2.50).\n",
        "\n",
        "Note the extra WHERE clauses."
      ]
    },
    {
      "metadata": {
        "id": "p4oSYFjKon4W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "EVERY_N = 100000\n",
        "\n",
        "trips = bq.query('''\n",
        "  SELECT\n",
        "    pickup_datetime,\n",
        "    pickup_longitude, pickup_latitude, \n",
        "    dropoff_longitude, dropoff_latitude,\n",
        "    passenger_count,\n",
        "    trip_distance,\n",
        "    tolls_amount,\n",
        "    fare_amount,\n",
        "    total_amount\n",
        "  FROM\n",
        "    `nyc-tlc.yellow.trips`\n",
        "  WHERE\n",
        "    MOD(ABS(FARM_FINGERPRINT(STRING(pickup_datetime))), %d) = 1\n",
        "    \n",
        "    #note that that trips with zero distance or \n",
        "    #costing less than $2.50 are excluded    \n",
        "    AND trip_distance > 0 AND fare_amount >= 2.5    \n",
        "    \n",
        "''' % (EVERY_N)).to_dataframe()\n",
        "\n",
        "ax = sns.regplot(x=\"trip_distance\", y=\"fare_amount\", fit_reg=False, ci=None, truncate=True, data=trips)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qdlYEvR1on4e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "What's up with the streaks at `$45` and `$50`?  Those are fixed-amount rides from JFK and La Guardia airports into anywhere in Manhattan, i.e. to be expected.\n",
        "\n",
        "Let's examine whether the toll amount is captured in the total amount."
      ]
    },
    {
      "metadata": {
        "id": "aKtSbgPAon4f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tollrides = trips[trips['tolls_amount'] > 0]\n",
        "tollrides[['tolls_amount', 'fare_amount',\t'total_amount']][:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kis9wBYmon4j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Looking a few samples above, it should be clear that the total amount reflects fare amount, toll and tip somewhat arbitrarily -- this is because when customers pay cash, the tip is not known.  So,  the sum of fare_amount + tolls_amount is what needs to be predicted.  Tips are discretionary and do not need to be included for fare estimation.\n",
        "\n",
        "Let's also look at the distribution of values within the columns."
      ]
    },
    {
      "metadata": {
        "id": "cZ3LugBSon4k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trips.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "guZWOj_Aon4o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Hmm ... The min, max of locations look strange. We shouldn't have zero values for location!"
      ]
    },
    {
      "metadata": {
        "id": "CBaC-497on40",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h3> Quality control and other preprocessing </h3>\n",
        "\n",
        "Some clean-up of the data is in order:\n",
        "<ol>\n",
        "<li>New York city longitudes are around -74 and latitudes are around 41.</li>\n",
        "<li>There shouldn't be zero passengers.</li>\n",
        "<li>Clean up the total_amount column to reflect only fare_amount and tolls_amount, and then remove those two columns.</li>\n",
        "<li>Before the ride starts, the pickup and dropoff locations are known but not the actual trip distance (that depends on the route taken), so remove it from the ML dataset</li>\n",
        "<li>Discard the timestamp</li>\n",
        "</ol>\n",
        "\n",
        "We could do this kind of preprocessing in BigQuery, similar to how we removed the zero-distance rides, but just to show you another option, let's do this in Python.  In production, we'll have to carry out the same preprocessing on the real-time input data. \n",
        "\n",
        "This sort of preprocessing of input data is quite common in ML, especially if the quality-control is dynamic."
      ]
    },
    {
      "metadata": {
        "id": "L86nL5YLon42",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocess(trips_in):\n",
        "  trips = trips_in.copy(deep=True)\n",
        "  trips.fare_amount = trips.fare_amount + trips.tolls_amount\n",
        "  del trips['tolls_amount']\n",
        "  del trips['total_amount']\n",
        "  del trips['trip_distance']\n",
        "  del trips['pickup_datetime']\n",
        "  qc = np.all([\\\n",
        "             trips['pickup_longitude'] > -78, \\\n",
        "             trips['pickup_longitude'] < -70, \\\n",
        "             trips['dropoff_longitude'] > -78, \\\n",
        "             trips['dropoff_longitude'] < -70, \\\n",
        "             trips['pickup_latitude'] > 37, \\\n",
        "             trips['pickup_latitude'] < 45, \\\n",
        "             trips['dropoff_latitude'] > 37, \\\n",
        "             trips['dropoff_latitude'] < 45, \\\n",
        "             trips['passenger_count'] > 0,\n",
        "            ], axis=0)\n",
        "  return trips[qc]\n",
        "\n",
        "tripsqc = preprocess(trips)\n",
        "tripsqc.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bbsRzcqLon46",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The quality control has removed about 300 rows (10700 - 10400) or about 3% of the data. This seems reasonable.\n",
        "\n",
        "In the next lab, you will move on to creating the ML datasets.\n",
        "\n",
        "<h3> Recap </h3>\n",
        "\n",
        "In this notebook, you used BigQuery APIs to sample data about taxi rides in New York City. Based on what you know about using hashing functions to retrieve reproducible samples, you practiced with SQL statements that have been implemented to use the FARM_FINGERPRINT hashing function to selectively and consistently filter out specific rows of data. Finally, you discovered bogus data and removed it from analysis using both SQL and Python based implementations."
      ]
    },
    {
      "metadata": {
        "id": "HVuX8oeMon5m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Copyright 2019 Counter Factual .AI LLC.\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
        "http://www.apache.org/licenses/LICENSE-2.0\n",
        "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
      ]
    }
  ]
}